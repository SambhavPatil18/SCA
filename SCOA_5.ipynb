{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy2S9muInGWk",
        "outputId": "8c70d172-7e8a-4b16-a85f-690eeb4ab461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Cluster Centroids: [[0.59754598 0.17170333]\n",
            " [0.1825933  0.71918648]\n",
            " [0.68880233 0.66659985]], Best Score: 10.678539870863613\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# PSO Parameters\n",
        "NUM_POINTS = 50  # Number of data points\n",
        "NUM_CLUSTERS = 3  # Number of clusters\n",
        "NUM_PARTICLES = 30\n",
        "NUM_ITERATIONS = 100\n",
        "INERTIA_WEIGHT = 0.5\n",
        "COGNITIVE_CONSTANT = 1.5\n",
        "SOCIAL_CONSTANT = 1.5\n",
        "\n",
        "# Randomly generate data points\n",
        "data_points = np.random.rand(NUM_POINTS, 2)  # 2D data points\n",
        "\n",
        "# Objective function to minimize the sum of squared distances\n",
        "def objective_function(centroids):\n",
        "    total_distance = 0\n",
        "    for point in data_points:\n",
        "        distances = [np.linalg.norm(point - centroid) for centroid in centroids]\n",
        "        total_distance += min(distances)\n",
        "    return total_distance\n",
        "\n",
        "# Initialize particles (each particle represents a set of cluster centroids)\n",
        "particles = [np.random.rand(NUM_CLUSTERS, 2) for _ in range(NUM_PARTICLES)]\n",
        "velocities = [np.random.uniform(-1, 1, (NUM_CLUSTERS, 2)) for _ in range(NUM_PARTICLES)]\n",
        "\n",
        "# Personal and global best positions and scores\n",
        "personal_best_positions = np.copy(particles)\n",
        "personal_best_scores = np.array([objective_function(p) for p in particles])\n",
        "\n",
        "global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n",
        "global_best_score = np.min(personal_best_scores)\n",
        "\n",
        "def particle_swarm_clustering():\n",
        "    global global_best_position, global_best_score\n",
        "\n",
        "    for iteration in range(NUM_ITERATIONS):\n",
        "        for i in range(NUM_PARTICLES):\n",
        "            velocities[i] = (INERTIA_WEIGHT * velocities[i] +\n",
        "                             COGNITIVE_CONSTANT * np.random.random() * (personal_best_positions[i] - particles[i]) +\n",
        "                             SOCIAL_CONSTANT * np.random.random() * (global_best_position - particles[i]))\n",
        "\n",
        "            particles[i] += velocities[i]\n",
        "\n",
        "            current_score = objective_function(particles[i])\n",
        "            if current_score < personal_best_scores[i]:\n",
        "                personal_best_positions[i] = particles[i]\n",
        "                personal_best_scores[i] = current_score\n",
        "\n",
        "                if current_score < global_best_score:\n",
        "                    global_best_position = particles[i]\n",
        "                    global_best_score = current_score\n",
        "\n",
        "    return global_best_position, global_best_score\n",
        "\n",
        "# Run the PSO clustering\n",
        "best_centroids, best_score = particle_swarm_clustering()\n",
        "print(f\"Best Cluster Centroids: {best_centroids}, Best Score: {best_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements **Particle Swarm Optimization (PSO)** to solve a clustering problem, akin to **k-means clustering**, by minimizing the sum of squared distances between data points and their closest centroids. Let's break it down step-by-step.\n",
        "\n",
        "---\n",
        "\n",
        "## **Code Walkthrough**\n",
        "\n",
        "### 1. **PSO Parameters**\n",
        "\n",
        "```python\n",
        "NUM_POINTS = 50           # Number of data points to cluster\n",
        "NUM_CLUSTERS = 3          # Number of clusters (k)\n",
        "NUM_PARTICLES = 30        # Number of particles in the swarm\n",
        "NUM_ITERATIONS = 100      # Number of iterations\n",
        "INERTIA_WEIGHT = 0.5      # Inertia weight (ω) to control the velocity\n",
        "COGNITIVE_CONSTANT = 1.5  # Cognitive component (φ1) for personal best influence\n",
        "SOCIAL_CONSTANT = 1.5     # Social component (φ2) for global best influence\n",
        "```\n",
        "\n",
        "These parameters define the characteristics of the PSO algorithm, including the swarm's behavior and convergence speed.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Generate Random Data Points**\n",
        "\n",
        "```python\n",
        "data_points = np.random.rand(NUM_POINTS, 2)  # Generate 2D data points\n",
        "```\n",
        "\n",
        "- Creates `NUM_POINTS` random data points in a 2D space with coordinates between 0 and 1.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Objective Function**\n",
        "\n",
        "```python\n",
        "def objective_function(centroids):\n",
        "    total_distance = 0\n",
        "    for point in data_points:\n",
        "        distances = [np.linalg.norm(point - centroid) for centroid in centroids]\n",
        "        total_distance += min(distances)  # Sum the minimum distance to the closest centroid\n",
        "    return total_distance\n",
        "```\n",
        "\n",
        "- This function calculates the total distance of all data points to their nearest cluster centroids.\n",
        "- The goal is to **minimize** this total distance, similar to the k-means objective.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Initialize Particles and Velocities**\n",
        "\n",
        "```python\n",
        "particles = [np.random.rand(NUM_CLUSTERS, 2) for _ in range(NUM_PARTICLES)]\n",
        "velocities = [np.random.uniform(-1, 1, (NUM_CLUSTERS, 2)) for _ in range(NUM_PARTICLES)]\n",
        "```\n",
        "\n",
        "- **Particles**: Each particle represents a candidate solution (a set of `NUM_CLUSTERS` centroids).\n",
        "- **Velocities**: Each particle's velocity is initialized with random values between -1 and 1 for each dimension.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Personal and Global Best**\n",
        "\n",
        "```python\n",
        "personal_best_positions = np.copy(particles)\n",
        "personal_best_scores = np.array([objective_function(p) for p in particles])\n",
        "\n",
        "global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n",
        "global_best_score = np.min(personal_best_scores)\n",
        "```\n",
        "\n",
        "- **Personal Best**: The best solution each particle has encountered so far.\n",
        "- **Global Best**: The best solution encountered by the entire swarm.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **PSO Clustering Function**\n",
        "\n",
        "```python\n",
        "def particle_swarm_clustering():\n",
        "    global global_best_position, global_best_score\n",
        "\n",
        "    for iteration in range(NUM_ITERATIONS):\n",
        "        for i in range(NUM_PARTICLES):\n",
        "            # Update velocity\n",
        "            velocities[i] = (INERTIA_WEIGHT * velocities[i] +\n",
        "                             COGNITIVE_CONSTANT * np.random.random() * (personal_best_positions[i] - particles[i]) +\n",
        "                             SOCIAL_CONSTANT * np.random.random() * (global_best_position - particles[i]))\n",
        "\n",
        "            # Update particle position\n",
        "            particles[i] += velocities[i]\n",
        "\n",
        "            # Evaluate the new position\n",
        "            current_score = objective_function(particles[i])\n",
        "\n",
        "            # Update personal best\n",
        "            if current_score < personal_best_scores[i]:\n",
        "                personal_best_positions[i] = particles[i]\n",
        "                personal_best_scores[i] = current_score\n",
        "\n",
        "                # Update global best\n",
        "                if current_score < global_best_score:\n",
        "                    global_best_position = particles[i]\n",
        "                    global_best_score = current_score\n",
        "\n",
        "    return global_best_position, global_best_score\n",
        "```\n",
        "\n",
        "#### **Key Steps:**\n",
        "\n",
        "1. **Update Velocities**:  \n",
        "   The velocity is updated using:\n",
        "   - The inertia term (`INERTIA_WEIGHT * velocities[i]`).\n",
        "   - The cognitive term (based on the particle's personal best).\n",
        "   - The social term (based on the swarm's global best).\n",
        "\n",
        "2. **Update Positions**:  \n",
        "   Add the updated velocity to each particle's position.\n",
        "\n",
        "3. **Evaluate Fitness**:  \n",
        "   Calculate the current score (objective function) for each particle.\n",
        "\n",
        "4. **Update Bests**:  \n",
        "   - If the current position is better than the particle's personal best, update it.\n",
        "   - If the current position is better than the global best, update it.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Run the PSO Clustering**\n",
        "\n",
        "```python\n",
        "best_centroids, best_score = particle_swarm_clustering()\n",
        "print(f\"Best Cluster Centroids: {best_centroids}, Best Score: {best_score}\")\n",
        "```\n",
        "\n",
        "- Runs the PSO clustering function and prints the final cluster centroids and the best score (sum of squared distances).\n",
        "\n",
        "---\n",
        "\n",
        "## **Sample Output**\n",
        "\n",
        "A sample output might look like:\n",
        "\n",
        "```plaintext\n",
        "Best Cluster Centroids: [[0.702, 0.518], [0.123, 0.348], [0.890, 0.732]], Best Score: 4.325\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **Considerations and Enhancements**\n",
        "\n",
        "1. **Visualization**:  \n",
        "   Plot the data points and the final centroids to visualize the clustering result:\n",
        "\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "\n",
        "   plt.scatter(data_points[:, 0], data_points[:, 1], c='blue', label='Data Points')\n",
        "   plt.scatter(best_centroids[:, 0], best_centroids[:, 1], c='red', marker='X', s=100, label='Centroids')\n",
        "   plt.legend()\n",
        "   plt.title(\"PSO Clustering Result\")\n",
        "   plt.xlabel(\"X Coordinate\")\n",
        "   plt.ylabel(\"Y Coordinate\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "2. **Parameter Tuning**:  \n",
        "   Experiment with `NUM_PARTICLES`, `NUM_ITERATIONS`, `INERTIA_WEIGHT`, `COGNITIVE_CONSTANT`, and `SOCIAL_CONSTANT` for better performance.\n",
        "\n",
        "3. **Constraints**:  \n",
        "   To keep centroids within the data bounds (e.g., between 0 and 1), consider bounding the particle updates:\n",
        "\n",
        "   ```python\n",
        "   particles[i] = np.clip(particles[i], 0, 1)\n",
        "   ```\n",
        "\n",
        "4. **Performance**:  \n",
        "   For larger datasets or higher-dimensional data, increasing the number of particles and iterations may improve results."
      ],
      "metadata": {
        "id": "rJpPuWkQbka_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghEt8L1hblif"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}