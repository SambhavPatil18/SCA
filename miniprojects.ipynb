{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEQnzTVqc66p",
        "outputId": "c11e3881-e8c3-4ade-d371-7a15c8c6f100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0: Best Fitness = 0.9800, Mutation Rate = 0.17, Crossover Rate = 0.83\n",
            "Generation 1: Best Fitness = 0.9800, Mutation Rate = 0.83, Crossover Rate = 0.83\n",
            "Generation 2: Best Fitness = 0.9800, Mutation Rate = 0.83, Crossover Rate = 0.83\n",
            "Generation 3: Best Fitness = 0.9800, Mutation Rate = 0.83, Crossover Rate = 0.83\n",
            "Generation 4: Best Fitness = 0.9800, Mutation Rate = 0.82, Crossover Rate = 0.82\n",
            "Generation 5: Best Fitness = 0.9800, Mutation Rate = 0.76, Crossover Rate = 0.76\n",
            "Generation 6: Best Fitness = 0.9800, Mutation Rate = 0.76, Crossover Rate = 0.24\n",
            "Generation 7: Best Fitness = 0.9800, Mutation Rate = 0.76, Crossover Rate = 0.76\n",
            "Generation 8: Best Fitness = 0.9800, Mutation Rate = 0.75, Crossover Rate = 0.75\n",
            "Generation 9: Best Fitness = 0.9800, Mutation Rate = 0.78, Crossover Rate = 0.22\n",
            "Generation 10: Best Fitness = 0.9800, Mutation Rate = 0.77, Crossover Rate = 0.23\n",
            "Generation 11: Best Fitness = 0.9800, Mutation Rate = 0.77, Crossover Rate = 0.23\n",
            "Generation 12: Best Fitness = 0.9800, Mutation Rate = 0.77, Crossover Rate = 0.23\n",
            "Generation 13: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "Generation 14: Best Fitness = 0.9867, Mutation Rate = 0.82, Crossover Rate = 0.18\n",
            "Generation 15: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 16: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "Generation 17: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "Generation 18: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 19: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 20: Best Fitness = 0.9867, Mutation Rate = 0.82, Crossover Rate = 0.18\n",
            "Generation 21: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 22: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 23: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 24: Best Fitness = 0.9867, Mutation Rate = 0.81, Crossover Rate = 0.19\n",
            "Generation 25: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "Generation 26: Best Fitness = 0.9867, Mutation Rate = 0.79, Crossover Rate = 0.21\n",
            "Generation 27: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "Generation 28: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "Generation 29: Best Fitness = 0.9867, Mutation Rate = 0.80, Crossover Rate = 0.20\n",
            "\n",
            "Best Hyperparameters: C = 35.9622, Gamma = 0.1183\n",
            "Best Cross-Validation Score: 0.9867\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import skfuzzy as fuzz\n",
        "from skfuzzy import control as ctrl\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# ---------------- Fitness Function ----------------\n",
        "def svm_fitness(C, gamma):\n",
        "    model = SVC(C=C, gamma=gamma)\n",
        "    accuracy = cross_val_score(model, X, y, cv=5).mean()\n",
        "    return accuracy\n",
        "\n",
        "# ---------------- Genetic Algorithm Parameters ----------------\n",
        "POPULATION_SIZE = 20\n",
        "GENERATIONS = 30\n",
        "MUTATION_STD = 0.1\n",
        "\n",
        "# Initialize random population of hyperparameters (C and gamma)\n",
        "def initialize_population(size):\n",
        "    population = []\n",
        "    for _ in range(size):\n",
        "        C = random.uniform(0.01, 100)\n",
        "        gamma = random.uniform(0.0001, 1)\n",
        "        population.append((C, gamma))\n",
        "    return population\n",
        "\n",
        "# Tournament selection\n",
        "def tournament_selection(population, fitnesses, k=3):\n",
        "    selected = random.sample(list(zip(population, fitnesses)), k)\n",
        "    selected.sort(key=lambda x: x[1], reverse=True)\n",
        "    return selected[0][0]\n",
        "\n",
        "# Blend crossover\n",
        "def blend_crossover(parent1, parent2, alpha=0.5):\n",
        "    C1 = alpha * parent1[0] + (1 - alpha) * parent2[0]\n",
        "    gamma1 = alpha * parent1[1] + (1 - alpha) * parent2[1]\n",
        "    C2 = alpha * parent2[0] + (1 - alpha) * parent1[0]\n",
        "    gamma2 = alpha * parent2[1] + (1 - alpha) * parent1[1]\n",
        "    return (C1, gamma1), (C2, gamma2)\n",
        "\n",
        "# Gaussian mutation\n",
        "def gaussian_mutation(individual, std=MUTATION_STD):\n",
        "    C = max(individual[0] + random.gauss(0, std), 0.0001)\n",
        "    gamma = max(individual[1] + random.gauss(0, std), 0.0001)\n",
        "    return (C, gamma)\n",
        "\n",
        "# Evaluate population\n",
        "def evaluate_population(population):\n",
        "    fitnesses = [svm_fitness(ind[0], ind[1]) for ind in population]\n",
        "    return fitnesses\n",
        "\n",
        "# Calculate population diversity\n",
        "def calculate_diversity(population):\n",
        "    C_values = [ind[0] for ind in population]\n",
        "    gamma_values = [ind[1] for ind in population]\n",
        "    return np.std(C_values) + np.std(gamma_values)\n",
        "\n",
        "# ---------------- Fuzzy Logic Control System ----------------\n",
        "\n",
        "# Define fuzzy inputs and outputs\n",
        "diversity = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'diversity')\n",
        "improvement = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'improvement')\n",
        "mutation_rate = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'mutation_rate')\n",
        "crossover_rate = ctrl.Consequent(np.arange(0, 1.1, 0.1), 'crossover_rate')\n",
        "\n",
        "# Membership functions for diversity\n",
        "diversity['low'] = fuzz.trimf(diversity.universe, [0, 0, 0.5])\n",
        "diversity['high'] = fuzz.trimf(diversity.universe, [0.5, 1, 1])\n",
        "\n",
        "# Membership functions for improvement\n",
        "improvement['low'] = fuzz.trimf(improvement.universe, [0, 0, 0.5])\n",
        "improvement['high'] = fuzz.trimf(improvement.universe, [0.5, 1, 1])\n",
        "\n",
        "# Membership functions for mutation rate\n",
        "mutation_rate['low'] = fuzz.trimf(mutation_rate.universe, [0, 0, 0.5])\n",
        "mutation_rate['high'] = fuzz.trimf(mutation_rate.universe, [0.5, 1, 1])\n",
        "\n",
        "# Membership functions for crossover rate\n",
        "crossover_rate['low'] = fuzz.trimf(crossover_rate.universe, [0, 0, 0.5])\n",
        "crossover_rate['high'] = fuzz.trimf(crossover_rate.universe, [0.5, 1, 1])\n",
        "\n",
        "# Fuzzy rules\n",
        "rule1 = ctrl.Rule(diversity['low'] & improvement['low'], (mutation_rate['high'], crossover_rate['low']))\n",
        "rule2 = ctrl.Rule(diversity['high'] & improvement['high'], (mutation_rate['low'], crossover_rate['high']))\n",
        "rule3 = ctrl.Rule(diversity['low'] & improvement['high'], (mutation_rate['low'], crossover_rate['low']))\n",
        "rule4 = ctrl.Rule(diversity['high'] & improvement['low'], (mutation_rate['high'], crossover_rate['high']))\n",
        "\n",
        "# Create and simulate the control system\n",
        "fuzzy_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4])\n",
        "fuzzy_system = ctrl.ControlSystemSimulation(fuzzy_ctrl)\n",
        "\n",
        "# ---------------- Main Genetic Algorithm ----------------\n",
        "\n",
        "def genetic_algorithm():\n",
        "    population = initialize_population(POPULATION_SIZE)\n",
        "    best_solution = None\n",
        "    best_fitness = 0\n",
        "    prev_best_fitness = 0\n",
        "\n",
        "    # Track fitness, C, and gamma over generations\n",
        "    fitness_history = []\n",
        "    C_history = []\n",
        "    gamma_history = []\n",
        "\n",
        "    for generation in range(GENERATIONS):\n",
        "        fitnesses = evaluate_population(population)\n",
        "        diversity_val = calculate_diversity(population)\n",
        "        best_gen_fitness = max(fitnesses)\n",
        "        improvement_val = max(0, best_gen_fitness - prev_best_fitness)\n",
        "\n",
        "        # Fuzzy system input\n",
        "        fuzzy_system.input['diversity'] = diversity_val\n",
        "        fuzzy_system.input['improvement'] = improvement_val\n",
        "        fuzzy_system.compute()\n",
        "\n",
        "        mut_rate = fuzzy_system.output['mutation_rate']\n",
        "        cross_rate = fuzzy_system.output['crossover_rate']\n",
        "\n",
        "        # Select next generation\n",
        "        new_population = []\n",
        "        for _ in range(POPULATION_SIZE // 2):\n",
        "            parent1 = tournament_selection(population, fitnesses)\n",
        "            parent2 = tournament_selection(population, fitnesses)\n",
        "\n",
        "            if random.random() < cross_rate:\n",
        "                offspring1, offspring2 = blend_crossover(parent1, parent2)\n",
        "            else:\n",
        "                offspring1, offspring2 = parent1, parent2\n",
        "\n",
        "            if random.random() < mut_rate:\n",
        "                offspring1 = gaussian_mutation(offspring1)\n",
        "                offspring2 = gaussian_mutation(offspring2)\n",
        "\n",
        "            new_population.extend([offspring1, offspring2])\n",
        "\n",
        "        population = new_population\n",
        "        prev_best_fitness = best_gen_fitness\n",
        "\n",
        "        # Track the best solution\n",
        "        if best_gen_fitness > best_fitness:\n",
        "            best_fitness = best_gen_fitness\n",
        "            best_solution = population[np.argmax(fitnesses)]\n",
        "\n",
        "        # Store data for visualization\n",
        "        fitness_history.append(best_fitness)\n",
        "        C_history.append(best_solution[0])\n",
        "        gamma_history.append(best_solution[1])\n",
        "\n",
        "        print(f\"Generation {generation}: Best Fitness = {best_fitness:.4f}, Mutation Rate = {mut_rate:.2f}, Crossover Rate = {cross_rate:.2f}\")\n",
        "\n",
        "    return best_solution, best_fitness, fitness_history, C_history, gamma_history\n",
        "\n",
        "# Run the Genetic Algorithm\n",
        "best_params, best_score, fitness_history, C_history, gamma_history = genetic_algorithm()\n",
        "print(f\"\\nBest Hyperparameters: C = {best_params[0]:.4f}, Gamma = {best_params[1]:.4f}\")\n",
        "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, let's break down the first code snippet which uses a Genetic Algorithm to optimize the hyperparameters of an SVM classifier for the Iris dataset, with Fuzzy Logic controlling the mutation and crossover rates.\n",
        "\n",
        "1. Initialization:\n",
        "\n",
        "Import necessary libraries: numpy, sklearn, random, matplotlib, and skfuzzy.\n",
        "Load the Iris dataset: datasets.load_iris() loads the dataset, and X and y store the features and target labels, respectively.\n",
        "Define the fitness function (svm_fitness): This function takes hyperparameters (C and gamma) as input, creates an SVM model with those parameters, and returns the model's cross-validation accuracy. This accuracy is used to evaluate the \"fitness\" of a set of hyperparameters.\n",
        "Set Genetic Algorithm parameters: POPULATION_SIZE, GENERATIONS, and MUTATION_STD control the size of the population, number of iterations, and mutation rate, respectively.\n",
        "Initialize the population (initialize_population): This function creates a random population of hyperparameter sets (C and gamma values) within specified ranges.\n",
        "2. Genetic Algorithm Operations:\n",
        "\n",
        "Tournament selection (tournament_selection): This function randomly selects a few individuals (hyperparameter sets) and returns the one with the highest fitness (accuracy). This simulates \"survival of the fittest.\"\n",
        "Blend crossover (blend_crossover): This function takes two parents (hyperparameter sets) and creates two offspring by blending their C and gamma values using a weighted average. This helps explore new areas of the hyperparameter space.\n",
        "Gaussian mutation (gaussian_mutation): This function introduces random changes to an individual's hyperparameters by adding noise drawn from a Gaussian distribution. This helps maintain diversity in the population and prevents premature convergence.\n",
        "Evaluate population (evaluate_population): This function calculates the fitness (accuracy) of each individual in the population using the svm_fitness function.\n",
        "Calculate diversity (calculate_diversity): This function measures the diversity of the population by calculating the standard deviation of C and gamma values. Diversity is important to avoid getting stuck in local optima.\n",
        "3. Fuzzy Logic Control:\n",
        "\n",
        "Define fuzzy inputs and outputs: Using skfuzzy, we define fuzzy variables for diversity, improvement, mutation rate, and crossover rate. These variables represent linguistic terms like \"low\" and \"high.\"\n",
        "Define membership functions: We assign membership functions to each fuzzy variable to define the degree to which a value belongs to a particular linguistic term. For example, a diversity value of 0.2 might have a high membership in the \"low\" category and a low membership in the \"high\" category.\n",
        "Define fuzzy rules: We create rules that relate the inputs to the outputs. For example, \"If diversity is low and improvement is low, then increase mutation rate and decrease crossover rate.\"\n",
        "Create and simulate the control system: We use skfuzzy to create a fuzzy logic controller and simulate its behavior. The controller takes diversity and improvement as inputs and outputs mutation and crossover rates.\n",
        "4. Main Genetic Algorithm Loop:\n",
        "\n",
        "The genetic_algorithm function runs the main loop of the algorithm:\n",
        "It initializes the population.\n",
        "It iterates for a fixed number of generations.\n",
        "In each generation, it evaluates the population, calculates diversity and improvement, uses the fuzzy system to adjust mutation and crossover rates, selects parents, performs crossover and mutation, and updates the population.\n",
        "It tracks the best solution found so far.\n",
        "Finally, it returns the best hyperparameters, best fitness, and data for visualization.\n",
        "5. Visualization (not included in the provided code but often done):\n",
        "\n",
        "The code could be extended to visualize the fitness over generations, the evolution of hyperparameters, and the fuzzy control surface. This helps understand how the algorithm is working and the impact of fuzzy logic.\n",
        "In summary, this code uses a Genetic Algorithm to find the optimal hyperparameters for an SVM classifier. The algorithm is enhanced with Fuzzy Logic to dynamically adjust the mutation and crossover rates based on the population's diversity and improvement over time. This adaptive approach can lead to better solutions and faster convergence. I hope this explanation is helpful for your viva! Good luck!"
      ],
      "metadata": {
        "id": "wPYinuqABute"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-8bkvC3D78ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-fuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubkXvNv5t4Tp",
        "outputId": "521e3c98-bfcb-408b-c33c-0b2b30211b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/920.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/920.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# ---------------- Load and Preprocess Data ----------------\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "y_one_hot = []\n",
        "for i in y:\n",
        "  if i == 0:\n",
        "    y_one_hot.append([1,0,0])\n",
        "  elif i == 1:\n",
        "    y_one_hot.append([0,1,0])\n",
        "  else:\n",
        "    y_one_hot.append([0,0,1])\n",
        "y_one_hot = np.array(y_one_hot)\n",
        "\n",
        "\n",
        "# Normalize the input data\n",
        "X_min, X_max = X.min(axis=0), X.max(axis=0)\n",
        "X_norm = (X - X_min) / (X_max - X_min)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---------------- Define Adaptive Fuzzy Membership Functions ----------------\n",
        "\n",
        "class AdaptiveFuzzyLayer(layers.Layer):\n",
        "    def __init__(self, num_mfs, input_dim):\n",
        "        super(AdaptiveFuzzyLayer, self).__init__()\n",
        "        self.num_mfs = num_mfs\n",
        "        self.input_dim = input_dim\n",
        "        # Initialize means and sigmas as trainable parameters for each feature\n",
        "        self.means = self.add_weight(name='means', shape=(input_dim, num_mfs), initializer='uniform', trainable=True)\n",
        "        self.sigmas = self.add_weight(name='sigmas', shape=(input_dim, num_mfs), initializer='uniform', trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Calculate Gaussian membership values for each feature and each membership function\n",
        "        expanded_inputs = tf.expand_dims(inputs, -1)  # Shape: (batch_size, input_dim, 1)\n",
        "        gaussians = tf.exp(-tf.square(expanded_inputs - self.means) / (2 * tf.square(self.sigmas)))\n",
        "        return gaussians\n",
        "\n",
        "# ---------------- Define Neuro-Fuzzy Model ----------------\n",
        "\n",
        "def create_neuro_fuzzy_model(num_mfs, input_dim, num_classes):\n",
        "    input_layer = layers.Input(shape=(input_dim,))\n",
        "    fuzzy_layer = AdaptiveFuzzyLayer(num_mfs, input_dim)(input_layer)  # Fuzzification layer\n",
        "    flatten_layer = layers.Flatten()(fuzzy_layer)\n",
        "    hidden_layer = layers.Dense(50, activation='relu')(flatten_layer)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(hidden_layer)  # For multi-class classification\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Define model parameters\n",
        "num_mfs = 3\n",
        "input_dim = X.shape[1]\n",
        "num_classes = y_one_hot.shape[1]\n",
        "\n",
        "# Create the Neuro-Fuzzy model\n",
        "model = create_neuro_fuzzy_model(num_mfs, input_dim, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ---------------- Train the Model ----------------\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "# ---------------- Evaluate the Model ----------------\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# ---------------- Predict and Plot Confusion Matrix ----------------\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "learned_means = model.layers[1].means.numpy()\n",
        "learned_sigmas = model.layers[1].sigmas.numpy()\n",
        "\n",
        "print(learned_means)\n",
        "print(learned_sigmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CdKk-TVRt76T",
        "outputId": "0e0f62dc-57c5-4806-e0d1-6527cb427973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.4183 - loss: 1.0617 - val_accuracy: 0.6000 - val_loss: 1.0520\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6231 - loss: 1.0297 - val_accuracy: 0.6000 - val_loss: 1.0251\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6723 - loss: 0.9804 - val_accuracy: 0.6000 - val_loss: 0.9948\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6627 - loss: 0.9653 - val_accuracy: 0.6000 - val_loss: 0.9620\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6762 - loss: 0.9355 - val_accuracy: 0.6000 - val_loss: 0.9277\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6877 - loss: 0.8738 - val_accuracy: 0.6000 - val_loss: 0.8924\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6825 - loss: 0.8298 - val_accuracy: 0.6000 - val_loss: 0.8595\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6533 - loss: 0.8470 - val_accuracy: 0.6000 - val_loss: 0.8303\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6731 - loss: 0.8240 - val_accuracy: 0.6333 - val_loss: 0.8038\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6919 - loss: 0.7547 - val_accuracy: 0.6333 - val_loss: 0.7809\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6804 - loss: 0.7721 - val_accuracy: 0.6333 - val_loss: 0.7617\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7138 - loss: 0.7205 - val_accuracy: 0.6333 - val_loss: 0.7452\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6648 - loss: 0.7370 - val_accuracy: 0.6333 - val_loss: 0.7312\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6450 - loss: 0.7585 - val_accuracy: 0.6333 - val_loss: 0.7191\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7179 - loss: 0.7140 - val_accuracy: 0.6333 - val_loss: 0.7083\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7033 - loss: 0.7177 - val_accuracy: 0.6333 - val_loss: 0.6988\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6888 - loss: 0.6618 - val_accuracy: 0.6333 - val_loss: 0.6901\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6575 - loss: 0.7001 - val_accuracy: 0.6333 - val_loss: 0.6819\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6690 - loss: 0.6921 - val_accuracy: 0.6333 - val_loss: 0.6741\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6773 - loss: 0.6798 - val_accuracy: 0.6333 - val_loss: 0.6665\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7033 - loss: 0.6420 - val_accuracy: 0.6333 - val_loss: 0.6589\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6658 - loss: 0.6695 - val_accuracy: 0.6333 - val_loss: 0.6512\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6669 - loss: 0.6217 - val_accuracy: 0.6333 - val_loss: 0.6436\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7085 - loss: 0.5915 - val_accuracy: 0.6333 - val_loss: 0.6356\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6762 - loss: 0.6167 - val_accuracy: 0.6333 - val_loss: 0.6271\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7190 - loss: 0.6082 - val_accuracy: 0.6333 - val_loss: 0.6184\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6627 - loss: 0.6021 - val_accuracy: 0.6333 - val_loss: 0.6093\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6710 - loss: 0.6036 - val_accuracy: 0.6333 - val_loss: 0.6000\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6575 - loss: 0.6137 - val_accuracy: 0.6333 - val_loss: 0.5908\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6304 - loss: 0.6206 - val_accuracy: 0.6333 - val_loss: 0.5820\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6637 - loss: 0.5619 - val_accuracy: 0.6333 - val_loss: 0.5736\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6627 - loss: 0.5583 - val_accuracy: 0.6333 - val_loss: 0.5657\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6919 - loss: 0.5623 - val_accuracy: 0.6333 - val_loss: 0.5585\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6898 - loss: 0.5348 - val_accuracy: 0.6333 - val_loss: 0.5519\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7033 - loss: 0.5228 - val_accuracy: 0.6333 - val_loss: 0.5456\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6523 - loss: 0.5506 - val_accuracy: 0.6333 - val_loss: 0.5396\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6960 - loss: 0.5161 - val_accuracy: 0.6333 - val_loss: 0.5343\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6617 - loss: 0.5074 - val_accuracy: 0.6333 - val_loss: 0.5291\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6471 - loss: 0.5338 - val_accuracy: 0.6333 - val_loss: 0.5242\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6940 - loss: 0.5203 - val_accuracy: 0.6333 - val_loss: 0.5198\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6898 - loss: 0.5041 - val_accuracy: 0.6333 - val_loss: 0.5157\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6513 - loss: 0.5214 - val_accuracy: 0.6333 - val_loss: 0.5115\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6637 - loss: 0.5035 - val_accuracy: 0.6667 - val_loss: 0.5079\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7025 - loss: 0.4836 - val_accuracy: 0.6667 - val_loss: 0.5047\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6712 - loss: 0.4931 - val_accuracy: 0.6667 - val_loss: 0.5015\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7350 - loss: 0.4633 - val_accuracy: 0.6667 - val_loss: 0.4987\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6631 - loss: 0.5080 - val_accuracy: 0.6667 - val_loss: 0.4958\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6621 - loss: 0.4889 - val_accuracy: 0.6667 - val_loss: 0.4929\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7215 - loss: 0.4681 - val_accuracy: 0.6667 - val_loss: 0.4911\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6985 - loss: 0.4741 - val_accuracy: 0.6667 - val_loss: 0.4889\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7017 - loss: 0.4895 - val_accuracy: 0.6667 - val_loss: 0.4865\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6808 - loss: 0.4624 - val_accuracy: 0.6667 - val_loss: 0.4838\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6808 - loss: 0.4852 - val_accuracy: 0.6667 - val_loss: 0.4810\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6944 - loss: 0.4891 - val_accuracy: 0.6667 - val_loss: 0.4780\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7235 - loss: 0.4450 - val_accuracy: 0.6667 - val_loss: 0.4740\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7152 - loss: 0.4444 - val_accuracy: 0.6667 - val_loss: 0.4697\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7267 - loss: 0.4163 - val_accuracy: 0.6667 - val_loss: 0.4654\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7069 - loss: 0.4731 - val_accuracy: 0.6667 - val_loss: 0.4603\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6871 - loss: 0.4596 - val_accuracy: 0.6667 - val_loss: 0.4551\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6917 - loss: 0.4457 - val_accuracy: 0.7000 - val_loss: 0.4495\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7335 - loss: 0.4284 - val_accuracy: 0.7333 - val_loss: 0.4438\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7412 - loss: 0.4354 - val_accuracy: 0.7333 - val_loss: 0.4383\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7890 - loss: 0.4302 - val_accuracy: 0.7667 - val_loss: 0.4333\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7702 - loss: 0.4247 - val_accuracy: 0.8000 - val_loss: 0.4285\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7502 - loss: 0.4436 - val_accuracy: 0.8667 - val_loss: 0.4246\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7429 - loss: 0.4388 - val_accuracy: 0.9333 - val_loss: 0.4209\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7660 - loss: 0.4337 - val_accuracy: 0.9333 - val_loss: 0.4174\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7802 - loss: 0.4219 - val_accuracy: 0.9000 - val_loss: 0.4138\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7981 - loss: 0.4524 - val_accuracy: 0.9000 - val_loss: 0.4103\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.4035 - val_accuracy: 0.9000 - val_loss: 0.4066\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7908 - loss: 0.4325 - val_accuracy: 0.9000 - val_loss: 0.4026\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7710 - loss: 0.4358 - val_accuracy: 0.9000 - val_loss: 0.3985\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7908 - loss: 0.4298 - val_accuracy: 0.9000 - val_loss: 0.3951\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8012 - loss: 0.4323 - val_accuracy: 0.9000 - val_loss: 0.3920\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7817 - loss: 0.4288 - val_accuracy: 0.9000 - val_loss: 0.3886\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7983 - loss: 0.4112 - val_accuracy: 0.9000 - val_loss: 0.3857\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8356 - loss: 0.3952 - val_accuracy: 0.9000 - val_loss: 0.3824\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7638 - loss: 0.4231 - val_accuracy: 0.9000 - val_loss: 0.3801\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.3743 - val_accuracy: 0.9000 - val_loss: 0.3773\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8106 - loss: 0.4106 - val_accuracy: 0.9000 - val_loss: 0.3746\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8356 - loss: 0.3913 - val_accuracy: 0.9000 - val_loss: 0.3721\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7846 - loss: 0.4155 - val_accuracy: 0.8667 - val_loss: 0.3707\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8096 - loss: 0.3939 - val_accuracy: 0.8667 - val_loss: 0.3681\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - loss: 0.4064 - val_accuracy: 0.8667 - val_loss: 0.3662\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8106 - loss: 0.4022 - val_accuracy: 0.8667 - val_loss: 0.3640\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8160 - loss: 0.4090 - val_accuracy: 0.8667 - val_loss: 0.3626\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7783 - loss: 0.4045 - val_accuracy: 0.8667 - val_loss: 0.3601\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8012 - loss: 0.3836 - val_accuracy: 0.8667 - val_loss: 0.3588\n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8077 - loss: 0.3888 - val_accuracy: 0.8667 - val_loss: 0.3574\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 0.4058 - val_accuracy: 0.8667 - val_loss: 0.3553\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8004 - loss: 0.3976 - val_accuracy: 0.8667 - val_loss: 0.3525\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8098 - loss: 0.3977 - val_accuracy: 0.8667 - val_loss: 0.3487\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8117 - loss: 0.3822 - val_accuracy: 0.8667 - val_loss: 0.3448\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8335 - loss: 0.3549 - val_accuracy: 0.8667 - val_loss: 0.3401\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8202 - loss: 0.3706 - val_accuracy: 0.9000 - val_loss: 0.3350\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7983 - loss: 0.4026 - val_accuracy: 0.8667 - val_loss: 0.3297\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7902 - loss: 0.3889 - val_accuracy: 0.9000 - val_loss: 0.3236\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8256 - loss: 0.3810 - val_accuracy: 0.9000 - val_loss: 0.3126\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8279 - loss: 0.3396 - val_accuracy: 0.9333 - val_loss: 0.2995\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8385 - loss: 0.3358 - val_accuracy: 0.9333 - val_loss: 0.2841\n",
            "Test Accuracy: 0.93\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.4052609e-02  2.2296086e-01  4.4324119e-02]\n",
            " [-4.3452669e-02 -3.5911780e-05  2.9463449e-01]\n",
            " [ 6.6876769e-02  7.4132189e-02  8.1968717e-02]\n",
            " [ 1.6884251e-01  3.4659922e-02  6.3562103e-02]]\n",
            "[[ 0.0453182  -0.19342628  0.00196619]\n",
            " [-0.00364938 -0.01788266 -0.26470923]\n",
            " [ 0.1002515  -0.09032373 -0.08667346]\n",
            " [ 0.22637694 -0.09497973  0.09167435]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, let's break down the second code snippet which builds and trains a Neuro-Fuzzy model using TensorFlow/Keras for the Iris dataset classification.\n",
        "\n",
        "1. Initialization and Data Preprocessing:\n",
        "\n",
        "Import libraries: numpy, matplotlib, tensorflow, sklearn, and pandas.\n",
        "Load the Iris dataset: datasets.load_iris() is used to load the dataset, with X and y storing features and target labels, respectively.\n",
        "One-hot encode target labels: The target labels (y) are converted into one-hot encoded format using manual loops, making them suitable for multi-class classification with the neural network.\n",
        "Normalize input data: The input features (X) are normalized to a range of 0 to 1 using min-max scaling. This helps improve the performance of the model.\n",
        "Split data into training and testing sets: train_test_split() is used to divide the data into training and testing sets, with 80% for training and 20% for testing.\n",
        "2. Define Adaptive Fuzzy Membership Functions:\n",
        "\n",
        "AdaptiveFuzzyLayer class: This custom Keras layer implements the fuzzification step of the Neuro-Fuzzy model.\n",
        "It takes the number of membership functions (num_mfs) and input dimension (input_dim) as parameters.\n",
        "It defines trainable weights for the means and standard deviations (sigmas) of Gaussian membership functions for each input feature.\n",
        "The call method calculates the membership values for each input data point using Gaussian functions based on the learned means and sigmas.\n",
        "This layer allows the fuzzy membership functions to adapt during training, improving the model's ability to capture complex relationships in the data.\n",
        "3. Define Neuro-Fuzzy Model:\n",
        "\n",
        "create_neuro_fuzzy_model function: This function defines the structure of the Neuro-Fuzzy model using Keras' functional API.\n",
        "It takes the number of membership functions, input dimension, and number of classes as parameters.\n",
        "It creates an input layer, followed by the AdaptiveFuzzyLayer for fuzzification.\n",
        "The output of the fuzzy layer is flattened and passed through a hidden layer with ReLU activation.\n",
        "Finally, an output layer with softmax activation is used for multi-class classification.\n",
        "This function creates a model that combines fuzzy logic with a neural network architecture.\n",
        "4. Compile and Train the Model:\n",
        "\n",
        "The model is compiled with the Adam optimizer, categorical cross-entropy loss function (suitable for multi-class classification), and accuracy as the evaluation metric.\n",
        "The model is trained using the fit method, providing the training data, number of epochs, and validation data.\n",
        "5. Evaluate and Predict:\n",
        "\n",
        "Evaluate the model: The evaluate method is used to assess the model's performance on the test data, calculating the test loss and accuracy.\n",
        "Predict and plot confusion matrix: The model is used to predict the classes for the test data. The predictions are compared with the true labels to generate a confusion matrix, which visualizes the model's performance in classifying different Iris species. The confusion matrix is displayed using ConfusionMatrixDisplay from sklearn.metrics.\n",
        "6. Extract Learned Parameters (optional):\n",
        "\n",
        "The code also includes lines to extract the learned means and sigmas of the Gaussian membership functions from the AdaptiveFuzzyLayer. This information can be used to understand how the fuzzy system has adapted to the data.\n",
        "In summary, this code demonstrates how to build and train a Neuro-Fuzzy model for Iris classification using TensorFlow/Keras. It leverages adaptive fuzzy membership functions to enhance the model's learning capabilities. The code also includes steps for evaluating the model's performance and visualizing its predictions using a confusion matrix. I hope this explanation is helpful for your viva! Good luck!\n",
        "\n",
        "Sources\n",
        "programtown.com/machine-learning-part-7-deep-learning-and-neural-networks/"
      ],
      "metadata": {
        "id": "9q0JilQPB_eg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0TkGN-A2_Qe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}